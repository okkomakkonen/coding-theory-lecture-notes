\documentclass[../main.tex]{subfiles}
\graphicspath{{\subfix{../images/}}}

\begin{document}

\section{Reed--Solomon codes}

In this section we will look at linear codes coming from polynomial evaluations. These codes include the family of Reed--Muller codes that we have seen in the previous section.

\subsection{Polynomial interpolation}

Let $n \geq 0$ be an integer and consider the vector space of polynomials of degree $< n$ over $\F_q$, denoted by $\F_q[x]^{< n}$. It is clear that the elements $1, x, \dots, x^{n-1}$ are linearly independent and span $\F_q[x]^{< n}$. Thus, $\dim(\F_q[x]^{< n}) = n$.

Let $\alpha \in \F_q$ and consider the evaluation map
\begin{equation*}
    \F_q[x] \to \F_q, \quad f \mapsto f(\alpha).
\end{equation*}
It is clear that this map is linear, since $(\lambda f + \mu g)(\alpha) = \lambda f(\alpha) + \mu g(\alpha)$ for $\lambda, \mu \in \F_q$ and $f, g \in \F_q[x]$. Similarly, if $\alpha_1, \dots, \alpha_n \in \F_q$ are distinct elements, then we can define the linear map, known as the \emph{evaluation map}, as
\begin{equation*}
    \ev \colon \F_q[x] \to \F_q^n, \quad f \mapsto \ev(f) = (f(\alpha_1), \dots, f(\alpha_n)).
\end{equation*}
Let $f \in \ker(\ev)$, \ie, $f(\alpha_i) = 0$ for $i = 1, \dots, n$. The polynomial $f$ has $n$ distinct roots, so it must have degree $\geq n$ or be the zero polynomial. By restricting the domain of $\ev$ to polynomials of degree $< n$, we get that $\ev$ is injective and $\dim(\ev(\F_q[x]^{< n})) = \dim(\F_q[x]^{< n}) = n$. This means that given any vector $\beta \in \F_q^n$, there exists a unique polynomial of degree $< n$ such that
\begin{equation*}
    f(\alpha_i) = \beta_i \quad \text{for all $i = 1, \dots, n$}.
\end{equation*}
The above fact is known as \emph{polynomial interpolation}. Let $\beta = e_j$ be a standard basis vector. Then we want to find a polynomial $f_j \in \F_q[x]^{< n}$ such that $f_j(\alpha_i) = 0$ for $i \neq j$ and $f_j(\alpha_j) = 1$. As the first try, let us use
\begin{equation*}
    f_j = \prod_{\substack{i = 1 \\ i \neq j}}^n (x - \alpha_i),
\end{equation*}
since this polynomial has roots at the required places and has $\deg(f_j) = n - 1$. It is clear that $f_j(\alpha_j) \neq 0$, so let us redefine $f_j$ by normalizing such that $f_j(\alpha_j) = 1$. Therefore,
\begin{equation*}
    f_j = \prod_{\substack{i = 1 \\ i \neq j}}^n \frac{x - \alpha_i}{\alpha_j - \alpha_i}
\end{equation*}
has the property that $f_j(\alpha_i) = 0$ for $i \neq j$ and $f_j(\alpha_j) = 1$. The above polynomials are known as \emph{Lagrange interpolation polynomials} and form a basis for $\F_q[x]^{< n}$ since $\ev(f_j) = e_j$ are linearly independent. For arbitrary $\beta \in \F_q^n$ we can just do linear combinations of the $f_j$'s to find the suitable polynomial that interpolates through the points $(\alpha_i, \beta_i)$:
\begin{equation*}
    f = \sum_{j=1}^n \beta_j f_j = \sum_{j=1}^n \beta_j \prod_{\substack{i = 1 \\ i \neq j}}^n \frac{x - \alpha_i}{\alpha_j - \alpha_i}.
\end{equation*}

\subsection{Univariate polynomial evaluation codes}

To use polynomial interpolation in coding theory we can regard the polynomial of degree $< k$ as the message and sample it at $k$ places. From the previous section we know that we can always fit a unique polynomial of degree $< k$ through these points, so we can recover the original polynomial. However, if some of the points gets moved (there are errors), then the associated polynomial will change. To still be able to recover the original polynomial we can instead sample the polynomial at $n \geq k$ places. Now, any $k$ of these $n$ places is sufficient to decode the original polynomial in case no errors have occurred. On the other hand, if errors have occurred, then we may look for a degree $< k$ polynomial that passes through the most number of the points. It turns out that this polynomial will be the original polynomial given that sufficiently few errors have occurred. We will formalize this type of code in the following.

Let $0 \leq k \leq n$ be an integer. Instead of considering the entire space $\F_q[x]^{< n}$ of polynomials of degree $< n$, let us consider the subspace $\F_q[x]^{< k}$. We can now define the \emph{Reed--Solomon code} as
\begin{equation*}
    \RS_k(\alpha) = \ev(\F_q[x]^{< k}) = \{ (f(\alpha_1), \dots, f(\alpha_n)) \mid f \in \F_q[x], \deg(f) < k \}.
\end{equation*}
Here $\alpha = (\alpha_1, \dots, \alpha_n) \in \F_q^n$ is the vector of \emph{evaluation points}.

\begin{theorem}\label{thm:RS_parameters}
The code $\RS_k(\alpha)$ is an $[n, k, n - k + 1]$ MDS code.
\end{theorem}

\begin{proof}
By injectivity of $\ev$, we get that $\dim(\ev(\F_q[x]^{< k})) = k$, so $\RS_k(\alpha)$ has dimension $k$. Furthermore, let $f \in \F_q[x]^{< k}$ be a nonzero polynomial. Then $\ev(f) \in \F_q^n$ has at most $k - 1$ zeros, so $\wt(\ev(f)) \geq n - k + 1$. On the other hand, the Singleton bound states that the minimum distance of an $[n, k]$ code is at most $n - k + 1$. Therefore, Reed--Solomon codes are MDS as they reach the Singleton bound.
\end{proof}

If $f = f_0 + f_1x + \dots + f_{k-1} x^{k-1}$, then $f(\alpha) = f_0 + f_1\alpha + \dots + f_{k-1} \alpha^{k-1}$. Therefore,
\begin{equation*}
    (f(\alpha_1), \dots, f(\alpha_n)) = (f_0, \dots, f_{k-1}) \underbrace{\begin{pmatrix}
        1 & \cdots & 1 \\
        \alpha_1 & \cdots & \alpha_n \\
        \vdots & \ddots & \vdots \\
        \alpha_1^{k-1} & \cdots & \alpha_n^{k-1}
    \end{pmatrix}}_{=G}.
\end{equation*}
Therefore, $G$ is a generator matrix for $\RS_k(\alpha)$. The transpose of $G$ above is known as a \emph{Vandermonde matrix}. It is well known that any $k \times k$ submatrix of an $n \times k$ Vandermonde matrix with distinct evaluation points $\alpha_1, \dots, \alpha_n$ is invertible. This also follows from the proof of Theorem~\ref{thm:dual_MDS}, since $\RS_k(\alpha)$ is MDS.

Consider just the points $\alpha_1, \dots, \alpha_k$ and denote the $j$th Lagrange interpolation polynomial by $\lambda_j$. From the earlier section we know that $f = \sum_{j=1}^k f(\alpha_j) \lambda_j$. Therefore,
\begin{equation*}
    (f(\alpha_1), \dots, f(\alpha_n)) = (f(\alpha_1), \dots, f(\alpha_k)) \underbrace{\begin{pmatrix}
        \lambda_1(\alpha_1) & \dots & \lambda_1(\alpha_n) \\
        \vdots & \ddots & \vdots \\
        \lambda_k(\alpha_1) & \dots & \lambda_k(\alpha_n)
    \end{pmatrix}}_{=G'}.
\end{equation*}
By using the property that $\lambda_j(\alpha_i) = \delta_{ij}$ we have that the above matrix can be written as
\begin{equation*}
    G' =
    \begin{pmatrix}
        1 & 0 & \cdots & 0 & \lambda_1(\alpha_{k+1}) & \cdots & \lambda_1(\alpha_n) \\
        0 & 1 & \cdots & 0 & \lambda_2(\alpha_{k+1}) & \cdots & \lambda_2(\alpha_n) \\
        \vdots & & \ddots & & \vdots & \ddots & \vdots \\
        0 & 0 & \cdots & 1 & \lambda_k(\alpha_{k+1}) & \cdots & \lambda_k(\alpha_n) \\
    \end{pmatrix}.
\end{equation*}
This is a generator matrix for $\RS_k(\alpha)$ in standard form.

It turns out that the dual of a Reed--Solomon code is not generally a Reed--Solomon code, but it will be equivalent to one. In particular, it will be a \emph{generalized Reed--Solomon code}. Define the generalized Reed--Solomon code as
\begin{equation*}
    \GRS_k(\alpha, \nu) = \{(\nu_1 f(\alpha_1), \dots, \nu_n f(\alpha_n)) \mid f \in \F_q[x], \deg(f) < k \},
\end{equation*}
where $\nu \in (\F_q^*)^n$ is a vector with nonzero entries known as the \emph{column multipliers}.

As Reed--Solomon codes of length $n$ require $n$ distinct evaluation points from $\F_q$, we have that $n \leq q$. Therefore, Reed--Solomon codes are bounded in length by the alphabet size.

We can consider also so-called \emph{extended Reed--Solomon} codes that are defined by the generator matrix
\begin{equation*}
    G = 
    \begin{pmatrix}
        1 & \cdots & 1 & 0\\
        \alpha_1 & \cdots & \alpha_n & 0 \\
        \vdots & \ddots & \vdots & 0 \\
        \alpha_1^{k-1} & \cdots & \alpha_n^{k-1} & 1
    \end{pmatrix},
\end{equation*}
where $\alpha_1, \dots, \alpha_n$ range over all elements in $\F_q$. Therefore, this code has length $n = q + 1$ and dimension $k$. Furthermore, any $k$ of the first $n$ columns are linearly independent. Finally, any $k - 1$ of the first $n$ columns and the last column are also linearly independent. Thus, any $k$ columns of $G$ are linearly independent, so the code generated by $G$ is MDS.

\subsection{Star products of codes}

We may define a product on vectors $x, y \in \F_q^n$ known as the \emph{star product} by
\begin{equation*}
    x \star y = (x_1y_1, \dots, x_ny_n).
\end{equation*}
Further, we may define the \emph{star product} of linear codes $\mathcal{C}, \mathcal{D} \subseteq \F_q^n$ as
\begin{equation*}
    \mathcal{C} \star \mathcal{D} = \spn\{ c \star d \mid c \in \mathcal{C}, d \in \mathcal{D} \}.
\end{equation*}
We take the span in the above definition to make sure that $\mathcal{C} \star \mathcal{D} \subseteq \F_q^n$ is a subspace.

Let $f, g \in \F_q[x]$ be polynomials and $\ev(f), \ev(g)$ be their evaluation vectors at some $n$ fixed points $\alpha_1, \dots, \alpha_n$. Then, $(\ev(f) \star \ev(g))_i = \ev(f)_i \ev(g)_i = f(\alpha_i)g(\alpha_i) = (fg)(\alpha_i) = \ev(fg)_i$, so $\ev(f) \star \ev(g) = \ev(fg)$. Similarly, $\ev(f) + \ev(g) = \ev(f + g)$.

Consider $f \in \F_q[x]^{< k}$ and $g \in \F_q[x]^{< \ell}$. Then, $fg \in \F_q[x]^{< k + \ell - 1}$, since
\begin{equation*}
    \deg(fg) = \deg(f) + \deg(g) \leq k - 1 + \ell - 1 < k + \ell - 1.
\end{equation*}
If $k + \ell - 1 > n$, then there is a polynomial $h$ of degree $< n$ that agrees with $fg$ at all points $\alpha_1, \dots, \alpha_n$. Therefore, $\RS_k(\alpha) \star \RS_\ell(\alpha) \subseteq \RS_{\min\{n, k + \ell - 1\}}(\alpha)$. Furthermore, $x^m$ for $m = 0, 1, \dots, \min\{n, k + \ell - 1\} - 1$ can be written as $x^i \cdot x^j = x^{i + j}$ for some $i \in \{0, 1, \dots, k - 1\}$ and $j \in \{0, 1, \dots, \ell - 1\}$. Hence, $\RS_k(\alpha) \star \RS_\ell(\alpha) = \RS_{\min\{n, k + \ell - 1\}}(\alpha)$. This can further be generalized to
\begin{equation*}
    \GRS_k(\alpha, \nu) \star \GRS_\ell(\alpha, \omega) = \GRS_{\min\{n, k + \ell - 1\}}(\alpha, \nu \star \omega).
\end{equation*}

The star products of codes are important in applications such as cryptanalysis, coded computation, and private information retrieval. For more properties of star product codes, see \cite{randriambololona2015products}.

% \begin{lemma}
% Let $\mathcal{C}, \mathcal{D} \subseteq \F_q^n$ be codes such that $\mathcal{C}$ has full support. Then,
% \begin{equation*}
%     \dim(\mathcal{C} \star \mathcal{D}) \geq \min\{ n, \dim(\mathcal{C}) + d^\perp(\mathcal{D}) - 2 \}.
% \end{equation*}
% \end{lemma}

% \begin{proof}
% Let $I \subseteq [n]$, $\lvert I \rvert = \dim(\mathcal{C})$ be an information set of $\mathcal{C}$. Let $J \subseteq [n] \setminus I$ be an arbitrary set of size $\lvert J \rvert = \min \{n - \dim(\mathcal{C}), d^\perp(\mathcal{D}) - 2\}$. Recall that we can find a codeword $c \in \mathcal{C}$ whose projection onto $I$ is arbitrary, since $I$ is an information set. Similary, we can find a codeword $d \in \mathcal{D}$ whose projection onto $J \cup \{i\}$ for any $i \in [n]$ is arbitrary, since $\lvert J \cup \{i\} \rvert \leq d^\perp(\mathcal{D}) - 1$.

% Let $i \in I$. Then there exists $c^{(i)} \in \mathcal{C}$ such that $c^{(i)}_i = 1$ and $c^{(i)}_k = 0$ for all $k \in I \setminus \{i\}$. Furthermore, there exists a codeword $d^{(i)} \in \mathcal{D}$ such that $d^{(i)}_i = 1$ and $d^{(i)}_j = 0$ for all $j \in J$. Then, $e^{(i)} = c^{(i)} \star d^{(i)} \in \mathcal{C} \star \mathcal{D}$ is such that $e^{(i)}_i = 1$ and $e^{(i)}_k = 0$ for all $k \in (I \cup J) \setminus \{i\}$.
% \begin{align*}
%     & \quad \: \overbrace{\phantom{mmmmmm}}^{I}~\overbrace{\phantom{mmmmm}}^{J} \\[-1.2em]
%     c^{(i)} &= \begin{matrix}
%         1 & 0 & \cdots & 0 & * & \cdots & *
%     \end{matrix} \\
%     d^{(i)} &= \begin{matrix}
%         1 & * & \cdots & * & 0 & \cdots & 0
%     \end{matrix} \\
%     c^{(i)} \star d^{(i)} &= \begin{matrix}
%         1 & 0 & \cdots & 0 & 0 & \cdots & 0
%     \end{matrix}
% \end{align*}

% Let $j \in J$. Then, there exists a codeword $c^{(j)} \in \mathcal{C}$ such that $c^{(j)}_j = 1$, since $\mathcal{C}$ has full support. Also, there exists a codeword $d^{(j)} \in \mathcal{D}$ such that $d^{(j)}_j = 1$ and $d^{(j)}_k = 0$ for all $k \in J \setminus \{j\}$. Thus, $c^{(j)} \star d^{(j)} \in \mathcal{C} \star \mathcal{D}$ is a codeword such that $(c^{(j)} \star d^{(j)})_j = 1$ and $(c^{(j)} \star d^{(j)})_k = 0$ for all $k \in J \setminus \{j\}$. By taking a linear combination of the vectors $e^{(i)}$ for all $i \in I$ and $c^{(j)} \star d^{(j)}$ we find a vector $e^{(j)} \in \mathcal{C} \star \mathcal{D}$ such that $e^{(j)}_j = 1$ and $e^{(j)}_k = 0$ for all $k \in (I \cup J) \setminus \{j\}$.
% \begin{align*}
%     & \quad \: \overbrace{\phantom{mmmmm}}^{I}~\overbrace{\phantom{mmmmmm}}^{J} \\[-1.2em]
%     c^{(j)} &= \begin{matrix}
%         * & \cdots & * & 1 & * & \cdots & *
%     \end{matrix} \\
%     d^{(j)} &= \begin{matrix}
%         * & \cdots & * & 1 & 0 & \cdots & 0
%     \end{matrix} \\
%     c^{(j)} \star d^{(j)} &= \begin{matrix}
%         * & \cdots & * & 1 & 0 & \cdots & 0
%     \end{matrix}
% \end{align*}

% The vectors $e^{i} \in \mathcal{C} \star \mathcal{D}$ for $i \in I \cup J$ are clearly linearly independent, so
% \begin{equation*}
%     \dim(\mathcal{C} \star \mathcal{D}) \geq \lvert I \cup J \rvert = \lvert I \rvert + \lvert J \rvert = \min\{n, \dim(\mathcal{C}) + d^\perp(\mathcal{D}) - 2 \}. \qedhere
% \end{equation*}
% \end{proof}

% \begin{theorem}[Product Singleton bound]
% Let $\mathcal{C}, \mathcal{D}$ be linear codes of length $n$ and full support. Then,
% \begin{equation*}
%     d(\mathcal{C} \star \mathcal{D}) \leq \max\{1, n - \dim(\mathcal{C}) - \dim(\mathcal{D}) + 2\}.
% \end{equation*}
% \end{theorem}

% \begin{proof}
% Let $c \in \mathcal{C}$, $d \in \mathcal{D}$ and $v \in (\mathcal{C} \star \mathcal{D})^\perp$. Then,
% \begin{equation*}
%     d \cdot (c \star v) = \sum_{i=1}^n d_i (c \star v)_i = \sum_{i=1}^n d_ic_i v_i = (c \star d) \cdot v = 0,
% \end{equation*}
% since $c \star d \in \mathcal{C} \star \mathcal{D}$. Hence, $c \star v \in \mathcal{D}^\perp$ and by linearity $\mathcal{C} \star (\mathcal{C} \star \mathcal{D})^\perp \subseteq \mathcal{D}^\perp$. Thus, by the Singleton bound, \todo{finish this proof}
% \end{proof}

\subsection{Decoding of Reed--Solomon codes}

In this section we will describe the Berlekamp--Welch algorithm for correcting errors in a Reed--Solomon code $\RS_k(\alpha)$. The minimum distance of $\RS_k(\alpha)$ is $d = n - k + 1$, so the unique decoding radius is $\lfloor \frac{n - k}{2} \rfloor$. Decoding generalized Reed--Solomon codes can be done by considering the vector $y' = \nu^{-1} \star y$, instead of $y$.

Let $y \in \F_q^n$ the received vector such that there exists $f \in \F_q[x]^{< k}$ with $d(\ev(f), y) \leq \lfloor \frac{n - k}{2} \rfloor$. Let $\mathcal{E} \subseteq [n]$, $\lvert \mathcal{E} \rvert = t$, be the location of the errors, \ie, $y_i = f(\alpha_i)$ if and only if $i \in [n] \setminus \mathcal{E}$. We will define an \emph{error-locator polynomial} that has roots at the error locations $\alpha_i$ for $i \in \mathcal{E}$. In particular, let $e \in \F_q[x]$ be a monic polynomial of degree $t$. Then we have that
\begin{equation*}
    y_i e(\alpha_i) = e(\alpha_i)f(\alpha_i)
\end{equation*}
for all $i \in [n]$. It is clear that the equation holds for $i \in [n] \setminus \mathcal{E}$. Furthermore, it is clear that for $i \in \mathcal{E}$, $e(\alpha_i) = 0$, so the equation holds. Define $r = -ef \in \F_q[x]$ to be a polynomial of degree $\leq t + k - 1$. We have the equation $y_i e(\alpha_i) + r(\alpha_i) = 0$ for all $i \in [n]$. We may write this as
\begin{equation*}
    y_i (e_0 + e_1\alpha_i + \dots e_{t - 1} \alpha_i^{t - 1}) + (r_0 + r_1 \alpha_1 + \dots + r_{t + k - 1}\alpha_i^{t + k - 1}) = -\alpha_i^t
\end{equation*}
as $e$ is monic of degree $t$. The above equation hold for all $i \in [n]$, so we may write
\begin{equation*}
    (e_0, \dots, e_{t-1}, r_0, \dots, r_{t + k - 1})\begin{pmatrix}
        y_1 & \cdots & y_n \\
        y_1 \alpha_1 & \cdots & y_n \alpha_n \\
        \vdots & \ddots & \vdots \\
        y_1 \alpha_1^{t-1} & \cdots & y_n \alpha_n^{t-1} \\
        1 & \cdots & 1 \\
        \alpha_1 & \cdots & \alpha_n \\
        \vdots & \ddots & \vdots \\
        \alpha_1^{t + k - 1} & \cdots & \alpha_n^{t + k - 1}
    \end{pmatrix}
    = -(\alpha_1^t, \dots, \alpha_n^t).
\end{equation*}
By definition of $y$ it is clear that this system has a solution\footnote{The received vector $y$ is assumed to contain at most $\lfloor \frac{n - k}{2} \rfloor$ errors.} that defines the polynomials $e$ and $r$. Thus, we may solve $f = -\frac{r}{e}$.

The coefficient matrix is $(2t + k) \times n$, so it will have nontrivial nullspace if $2t + k > n$, \ie, if $t > \frac{n - k}{2}$. On the other hand, we know that there can not be multiple solutions for $f$ if $t \leq \lfloor \frac{d - 1}{2} \rfloor = \lfloor \frac{n - k}{2} \rfloor$. Thus, if $t \leq \lfloor \frac{n - k}{2} \rfloor$, then the above has a unique solution for the message polynomial $f$.

\subsection{Multivariate polynomial evaluation codes}

Recall the recursive definition of binary Reed--Muller codes from the previous section. We may also see these codes as evaluation codes of subspaces of $\F_2[x_1, \dots, x_m]$. Let $n = 2^m$ and $P_1, \dots, P_n$ be all the points in $\F_2^m$. Then, define
\begin{equation*}
    \RM(r, m) = \{ (f(P_1), \dots, f(P_n)) \mid f \in \F_2[x_1, \dots, x_m], \deg(f) \leq r \}.
\end{equation*}

Let us show that this definition satisfies the recursive formula for the Reed--Muller codes. From the definition,
\begin{equation*}
    \RM(0, m) = \{ (f(P_1), \dots, f(P_n)) \mid f \in \F_2[x_1, \dots, x_m], \deg(f) \leq 0 \} = \{ (\lambda, \dots, \lambda) \mid \lambda \in \F_2 \},
\end{equation*}
since $\deg(f) \leq 0$ implies that $f$ is a constant. Furthermore, let $r = m$. Consider the polynomials $f = (x_1 - \alpha_1 - 1) \cdots (x_m - \alpha_m - 1)$ of degree $m = r$. Then $f(P) = 0$ if and only if $P \neq (\alpha_1, \dots, \alpha_m)$. Hence, the evaluation vector of $f$ is all zeros, except at the point $P_i = (\alpha_1, \dots, \alpha_m)$. Therefore, the linear code contains the standard basis vectors of $\F_2^{2^m}$ so it is the full space code $\F_2^{2^m}$.

Let $f \in \F_2[x_1, \dots, x_m]$, $\deg(f) \leq r$. As we only care about the evaluation vector of $f$, we may assume that $f$ contains no higher powers of $x_i$, since $\beta^j = \beta$ for all $\beta \in \F_2$ and $j = 1, 2, \dots$. Then we can write $f = g + x_m h$, where $g, h \in \F_2[x_1, \dots, x_{m-1}]$, $\deg(g) \leq r$, $\deg(h) \leq r - 1$. Without loss of generality, interpret $P_1, \dots, P_n$ as binary representations of integers (where $(1, 0, \dots, 0)$ corresponds to 1) and order them accordingly, \ie, $P_1 = (0, 0, \dots, 0), P_2 = (1, 0, \dots, 0), \dots, P_n = (1, 1, \dots, 1)$. Therefore,
\begin{equation*}
    \ev(f) = \ev(g + x_m h) = (\ev_0(g + x_m h), \ev_1(g + x_m h)) = (\ev_0(g), \ev_1(g) + \ev_1(h)),
\end{equation*}
where $\ev_0$ and $\ev_1$ are the evaluation functions on the points where $x_m = 0$ and $x_m = 1$, respectively. Furthermore, $\ev_0(g) = \ev_1(g)$ and $\ev_1(h)$ are the evaluation vectors of $g$ and $h$ on all points in $\F_2^{2^{m-1}}$, since $g, h \in \F_2[x_1, \dots, x_{m-1}]$. From the final step we see that the codeword is of the form $(u, u + v)$, where $u \in \RM(r, m - 1)$ and $v \in \RM(r-1, m-1)$. Therefore, this definition also satisfies the recursive formula, so it matches with the earlier description of Reed--Muller codes.

\end{document}